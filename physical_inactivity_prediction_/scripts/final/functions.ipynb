{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import gpxo\n",
    "import gpxpy\n",
    "import gpxpy.gpx\n",
    "import fitdecode\n",
    "import warnings\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Suppress FutureWarning messages\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering para arquivos Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_processed_data(folder_path):\n",
    "\n",
    "    '''Função para ler todas as atividades do atleta com arquivos no formato json e a partir disso retornar um conjunto com as features criadas'''\n",
    "\n",
    "    # Contador de arquivos dentro da pasta\n",
    "    files_count = 0\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        files_count += 1\n",
    "\n",
    "    # Caminho do arquivo de atividade com {} para inserir o número\n",
    "    # Nome do arquivo no formato: atividades(x).json onde x >= n.\n",
    "    filename = \"atividades ({}).json\"\n",
    "\n",
    "    full_path = os.path.join(folder_path, filename)  \n",
    "    n = 1 # Se as atividades começarem por ex com 0, então mudar para n = 0.\n",
    "\n",
    "    # Leitura de cada uma das atividades no formato json com json.load. \n",
    "    activities_data = [json.load(open(full_path.format(activity),\"rb\")) for activity in range(n, files_count + n)]\n",
    "\n",
    "    df = pd.DataFrame(activities_data)\n",
    "\n",
    "    # Lista das metricas que serão identificadas\n",
    "    metrics = ['distance', 'pace', 'speed']\n",
    "\n",
    "    # Dicionário com as features que serão criadas com o valor de cada atividade\n",
    "    df_athlete_dict = {\n",
    "        'total_distance (km)': [], \n",
    "        'pace (min/km)': [],\n",
    "        'velocity (km/h)': []    \n",
    "    }\n",
    "\n",
    "    # Iteração no número de atividades\n",
    "    for activity in range(len(df)):\n",
    "        # Iteração para encontrar a linha com a métrica desejada e adicionar seu valor no dicionário com a chave certa\n",
    "        for values in df['summaries'][activity]: # por atividade\n",
    "            if (values['metric'] == metrics[0]): \n",
    "                df_athlete_dict['total_distance (km)'].append(round(values['value'],2))\n",
    "            elif (values['metric'] == metrics[1]):\n",
    "                df_athlete_dict['pace (min/km)'].append(round(values['value'],2))\n",
    "            elif (values['metric'] == metrics[2]):\n",
    "                df_athlete_dict['velocity (km/h)'].append(round(values['value'],2))\n",
    "\n",
    "    # Criação do DataFrame de atividades\n",
    "    df_athlete_activities = pd.DataFrame(df_athlete_dict)\n",
    "\n",
    "    # Tempo inicial da atividade\n",
    "    start = pd.to_datetime(df['start_epoch_ms'],unit='ms').dt.tz_localize('UTC').dt.tz_convert('America/Sao_Paulo').dt.tz_localize(None).dt.round('s')\n",
    "\n",
    "    # Tempo final da atividade\n",
    "    end = pd.to_datetime(df['end_epoch_ms'],unit='ms').dt.tz_localize('UTC').dt.tz_convert('America/Sao_Paulo').dt.tz_localize(None).dt.round('s')\n",
    "\n",
    "    # Criação da coluna com tempo total em minutos a partir da subtração dos tempos final e inicial\n",
    "    df_athlete_activities['total_time (min)'] = (end - start).apply(lambda x: x.total_seconds() // 60)\n",
    "\n",
    "    # Criando a coluna para a data da atividade\n",
    "    df_athlete_activities.insert(0, 'activity_date', pd.to_datetime(df['end_epoch_ms'],unit='ms').dt.tz_localize('UTC').dt.tz_convert('America/Sao_Paulo').dt.tz_localize(None).dt.round('d'))\n",
    "\n",
    "    return df_athlete_activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering para arquivos Gpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpx_processed_data(folder_path):\n",
    "\n",
    "    '''Função para ler todas as atividades do atleta com arquivos no formato gpx e a partir disso retornar um conjunto com as features criadas'''\n",
    "\n",
    "    # Dicionário com as features que serão criadas com o valor de cada atividade\n",
    "    df_athlete_dict = {\n",
    "        'activity_date': [],\n",
    "        'total_distance (km)': [], \n",
    "        'total_time (min)': [],\n",
    "        'pace (min/km)': [],\n",
    "        'velocity (km/h)': []    \n",
    "    }\n",
    "\n",
    "    # Itera por cada arquivo na pasta\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Junta o nome do arquivo com o caminho da pasta\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Lê o arquivo no formato gpx com a biblioteca gpxo e transforma em df\n",
    "        gpx = gpxo.Track(full_path).data.reset_index()    \n",
    "\n",
    "        '''Cocantenação de elementos novos para cada feature no df, a cada iteração'''\n",
    "\n",
    "        # Data da atividade (a partir da primeira linha do df original com os pontos marcados)\n",
    "        df_athlete_dict['activity_date'].append(gpx['time'][0].round('d'))\n",
    "\n",
    "        # Distância total em km\n",
    "        total_dist = gpx['distance (km)'].max()\n",
    "        df_athlete_dict['total_distance (km)'].append(round(total_dist,2))\n",
    "\n",
    "        # Tempo total em minutos\n",
    "        total_min = (gpx['time'].max() - gpx['time'].min()).total_seconds() // 60\n",
    "        df_athlete_dict['total_time (min)'].append(total_min)\n",
    "\n",
    "        # Ritmo geral da atividade\n",
    "        df_athlete_dict['pace (min/km)'].append(round(total_min / total_dist, 2))\n",
    "\n",
    "        # Velocidade em km/h\n",
    "        df_athlete_dict['velocity (km/h)'].append(round(total_dist / (total_min / 60),2))\n",
    "    \n",
    "    # Passando o dicionário com as features criadas para um Dataframe\n",
    "    df_athlete_activities = pd.DataFrame(df_athlete_dict)\n",
    "    \n",
    "    return df_athlete_activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering para arquivos Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_processed_data(folder_path):\n",
    "    '''Função para ler todas as atividades do atleta com arquivos no formato fit e a partir disso retornar um conjunto com as features criadas'''\n",
    "\n",
    "    # Dicionário com as features que serão criadas com o valor de cada atividade\n",
    "    df_athlete_dict = {\n",
    "        'activity_date': [],\n",
    "        'total_distance (km)': [], \n",
    "        'total_time (min)': [],\n",
    "        'pace (min/km)': [],\n",
    "        'velocity (km/h)': []    \n",
    "    }\n",
    "\n",
    "    # Itera por cada arquivo na pasta\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Junta o nome do arquivo com o caminho da pasta\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Acessando o arquivo fit com função de leitura para obter os dados\n",
    "        with fitdecode.FitReader(full_path) as fit_file:\n",
    "            # Iterando for cada frame no arquivo fit\n",
    "            for frame in fit_file:\n",
    "                # Condição para o frame que contém os dados gps\n",
    "                if frame.frame_type == fitdecode.FIT_FRAME_DATA:\n",
    "                    # Condição para acessar o frame envolvendo métricas resumidas da sessão\n",
    "                    if frame.name == 'session':\n",
    "                        # Iteração pelos campos que possuem as métricas\n",
    "                        for field in frame.fields:\n",
    "                            # Condição para acessar o campo de start_time\n",
    "                            if field.name == 'start_time':\n",
    "                                df_athlete_dict['activity_date'].append(field.value)\n",
    "\n",
    "                            # Condição para acessar o campo de total_distance\n",
    "                            elif field.name == 'total_distance':\n",
    "                                total_dist_km = field.value / 1000\n",
    "                                df_athlete_dict['total_distance (km)'].append(round((total_dist_km),2))\n",
    "\n",
    "                            # Condição para acessar o campo de total_timer_time\n",
    "                            elif field.name == 'total_timer_time':\n",
    "                                total_time_min = field.value // 60\n",
    "                                df_athlete_dict['total_time (min)'].append(total_time_min)\n",
    "\n",
    "        # Condição para caso a distância seja 0, por causa da divisão\n",
    "        if total_dist_km == 0:\n",
    "            df_athlete_dict['pace (min/km)'].append(0)\n",
    "        else:    \n",
    "            df_athlete_dict['pace (min/km)'].append(round((total_time_min / total_dist_km),2))\n",
    "\n",
    "        df_athlete_dict['velocity (km/h)'].append(round(total_dist_km / (total_time_min / 60),2))\n",
    "    \n",
    "    # Passando o dicionário com as features criadas para um Dataframe\n",
    "    df_athlete_activities = pd.DataFrame(df_athlete_dict)\n",
    "\n",
    "    # Convertendo a coluna de data para o fuso horário local e arrendado em dias\n",
    "    df_athlete_activities['activity_date'] = df_athlete_activities['activity_date'].dt.tz_convert('America/Sao_Paulo').dt.tz_localize(None).dt.round('d')\n",
    "\n",
    "    return df_athlete_activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering of time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activities_time_frequency(df_athlete_activities):\n",
    "\n",
    "    # Dropando linhas com datas duplicadas\n",
    "    df_athlete_activities.drop_duplicates(subset='activity_date', inplace= True)\n",
    "\n",
    "    # Ordenando a data da menor pra maior e resetando index \n",
    "    df_athlete_activities.sort_values('activity_date', ascending=True, inplace=True)    \n",
    "    df_athlete_activities.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Criando uma coluna para o tipo de atividade e designando todas como Atividade\n",
    "    df_athlete_activities.insert(1, 'activity_type', 'Activity')\n",
    "\n",
    "    # Fazendo a diferença entre a atividade seguinte e a anterior e preenchendo a primeira linha com 0\n",
    "    df_athlete_activities['days_between_activities'] = df_athlete_activities['activity_date'].diff(periods=1).fillna(datetime.timedelta(days=1))\n",
    "\n",
    "    # Alterando o tipo da coluna para int\n",
    "    df_athlete_activities['days_between_activities'] = (df_athlete_activities['days_between_activities'].dt.days) - 1\n",
    "\n",
    "    # Data da primeira atividade\n",
    "    start = df_athlete_activities['activity_date'].iloc[0]\n",
    "\n",
    "    # Data da última atividade\n",
    "    end = df_athlete_activities['activity_date'].iloc[-1]\n",
    "\n",
    "    # Dias entre a primeira e última atividade\n",
    "    dates = pd.date_range(start, end, freq='d').round('d')\n",
    "\n",
    "    # Colocando todas as datas em um df\n",
    "    df_dates = pd.DataFrame({'activity_date': dates})\n",
    "\n",
    "    # Right join pra poder manter os dados das atividades existentes mas adicionar linhas para os novos dias\n",
    "    df_athlete_activities = df_dates.merge(df_athlete_activities, on='activity_date', how='left')\n",
    "\n",
    "    # Preechendo os valores nulos como Dia sem atividade\n",
    "    df_athlete_activities['activity_type'].fillna('No Activity', inplace=True)\n",
    "\n",
    "    # Preenchendo os valores NaN com 1 para poder fazer uma subtração cumulativa\n",
    "    df_athlete_activities['days_between_activities'].fillna(-1, inplace= True)\n",
    "\n",
    "    # Fazendo cumsum com valores negativos e depois multiplicando por -1 pra transformá-los em positivos\n",
    "    df_athlete_activities['days_between_activities'] = df_athlete_activities['days_between_activities'].cumsum() * -1\n",
    "\n",
    "    # Transformando em int pra evitar -0 ao invés de 0\n",
    "    df_athlete_activities['days_between_activities'] = df_athlete_activities['days_between_activities'].astype(int)\n",
    "\n",
    "    return df_athlete_activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drift_detection(df_example, drift_method_obj, results, param, drift_method, x, param_combination_count, example_id):\n",
    "    # Lista para obter todos os indexes que houver drift\n",
    "    drifts = []\n",
    "    df = df_example.copy()\n",
    "\n",
    "    # Index da ultima atividade do atleta antes da desistência/inatividade física\n",
    "    last_activity_index = df[df['activity_type'] == 1].iloc[-1].name    \n",
    "\n",
    "    # Range de x dias antes da última atividade\n",
    "    range_x_before_activity = [last_activity_index - value if last_activity_index >= value else 0 for value in range(0, x + 1)]\n",
    "    # Range de x dias depois da última atividade\n",
    "    range_x_after_activity = [last_activity_index + value for value in range(1, x + 1)]\n",
    "    # Lista com o range de indexes possíveis para classificar um drift como TP\n",
    "    drift_range = list(set(range_x_before_activity + range_x_after_activity))\n",
    "    # Ordenação da lista de range de indexes do menor para o maior\n",
    "    drift_range.sort()\n",
    "\n",
    "    # Criando coluna no df com classificação 1 para todos os indexes que estiverem dentro do range de drift\n",
    "    df.loc[drift_range,'drift_possibility_range'] = 1\n",
    "    # Classificando como 0 os indexes fora do range\n",
    "    df['drift_possibility_range'].fillna(0, inplace=True)\n",
    "\n",
    "    # Iteração pelo df atualizado a cada linha para encontrar drifts\n",
    "    for index, row in df.iterrows():\n",
    "            drift_method_obj.update(row['days_between_activities'])\n",
    "            if drift_method_obj.drift_detected:\n",
    "                drifts.append(index)\n",
    "    \n",
    "    # Criando coluna no df com classificação 1 para onde houver drift \n",
    "    df.loc[drifts,'drift_classification'] = 1\n",
    "    # Classificando como 0 onde não houve drift\n",
    "    df['drift_classification'].fillna(0, inplace=True)\n",
    "\n",
    "    # Condição para filtrar uma linha que haja um drift TP\n",
    "    TP_condition = (df['drift_possibility_range'] == 1) & (df['drift_classification'] == 1)\n",
    "\n",
    "    # Condição para caso haja um ou mais drift TP\n",
    "    if (TP_condition).sum() != 0:\n",
    "        # Selecionando o primeiro drift TP\n",
    "        first_TP_drift = df.loc[TP_condition, 'activity_date'].iloc[0]\n",
    "        # Selecionando a última linha (Onde ocorreu a desistência/Inatividade física)\n",
    "        end = df['activity_date'].iloc[-1]\n",
    "        # Obtendo a quantidade de dias em que foi previsto o primeiro drift TP antes da desistência/Inatividade física\n",
    "        days_of_first_DD_before_PI = (end - first_TP_drift).days\n",
    "    else:\n",
    "        # Caso não haja drift TP, a variável possui valor NaN\n",
    "        days_of_first_DD_before_PI = np.nan\n",
    "\n",
    "    # Adicionando na lista results a avaliação do drift detection\n",
    "    evaluation = evaluate(df, param, drift_method, days_of_first_DD_before_PI, param_combination_count, example_id)\n",
    "    results.append(evaluation) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift Detection Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df, drift_params, drift_method, days_of_first_DD_before_PI, param_combination_count, example_id):\n",
    "    # Definição de TP, FP, TN e FN como zero, inicialmente\n",
    "    TP = FP = TN = FN = 0 \n",
    "    \n",
    "    # Iteração pelo df a cada linha para classificar como TP, TN ou FP\n",
    "    for index, row in df.iterrows():\n",
    "        if (row['drift_possibility_range'] == 0) & (row['drift_classification'] == 0):\n",
    "            TN +=1\n",
    "\n",
    "        elif (row['drift_possibility_range'] == 0) & (row['drift_classification'] == 1):\n",
    "            FP +=1\n",
    "\n",
    "        elif (row['drift_possibility_range'] == 1) & (row['drift_classification'] == 1):\n",
    "            TP +=1\n",
    "    # Caso o TP fosse 0, significa que houve FN\n",
    "    if (TP == 0):\n",
    "        FN = 1\n",
    "    # Caso o TP fosse >= 1, não houve FN pois o(s) drift(s) foram detectados\n",
    "    elif (TP >= 1):\n",
    "        FN = 0\n",
    "    \n",
    "    # Valores que serão retornados da função\n",
    "    return {\n",
    "        'Parameter Combination id': param_combination_count,\n",
    "        'Example id': example_id,\n",
    "        'Example': df,\n",
    "        'Drift Parameters': drift_params,\n",
    "        'Drift Method': drift_method,\n",
    "        'Days of First DD before PI': days_of_first_DD_before_PI,\n",
    "        'TP': TP,\n",
    "        'TN': TN,\n",
    "        'FP': FP,\n",
    "        'FN': FN,\n",
    "    }      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(TP, FP, TN, FN):\n",
    "\n",
    "    # Calcular a precisão\n",
    "    if (TP + FP) != 0:\n",
    "        precision = TP / (TP + FP)\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    # Calcular o recall\n",
    "    if (TP + FN) != 0:\n",
    "        recall = TP / (TP + FN)\n",
    "    else:\n",
    "        recall = 0\n",
    "    \n",
    "    # Calcular o F1-score\n",
    "    if (precision + recall) != 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    return round(precision,2), round(recall,2), round(f1,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
