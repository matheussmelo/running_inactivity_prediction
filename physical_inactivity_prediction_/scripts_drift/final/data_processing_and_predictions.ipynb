{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from river import drift\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Leitura do arquivo com as funções necessárias pro pré-processamento e processamento do dados '''\n",
    "# json_processed_data(folder_path), gpx_processed_data(data_folder_path) e fit_processed_data(data_folder_path)\n",
    "%run C:/Users/USER/Desktop/EstudosDados/Projetos/Corrida/physical_inactivity_prediction/scripts/final/functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Contador de arquivos dentro da pasta '''\n",
    "\n",
    "# Caminho da pasta com as pastas contendo as atividades de cada atleta\n",
    "data_folders_path = 'C:/Users/USER/Desktop/EstudosDados/Projetos/Corrida/physical_inactivity_prediction/athletes_activities'\n",
    "\n",
    "folders_count = 0\n",
    "\n",
    "for file in os.listdir(data_folders_path):\n",
    "    folders_count += 1\n",
    "\n",
    "print(folders_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do Dataframe que terá os valores de cada atleta por id\n",
    "df_athletes_activities = pd.DataFrame()\n",
    "\n",
    "# Número do primeiro id (Se começar com 0, mudar para n = 0)\n",
    "n = 1\n",
    "\n",
    "# Iteração para criar o Dataframe com os valores de cada atleta por id\n",
    "for athlete_id in range(n, folders_count + n):\n",
    "\n",
    "    # Nome do arquivo com os dados do atleta\n",
    "    athlete_foldername = f'athlete{athlete_id}'\n",
    "\n",
    "    # Junção da pasta com as pastas contendo as atividades de cada atleta e o nome da pasta com os dados do atleta por id\n",
    "    data_folder_path = os.path.join(data_folders_path, athlete_foldername)\n",
    "\n",
    "    # Pegando a primeira atividade da pasta\n",
    "    first_file = os.listdir(data_folder_path)[0]\n",
    "    \n",
    "    if first_file.endswith('.gpx'):\n",
    "        # Criação do Dataframe a partir da função de processamento de dados gpx\n",
    "        df = gpx_processed_data(data_folder_path)\n",
    "\n",
    "    elif first_file.endswith('.json'):\n",
    "        # Criação do Dataframe a partir da função de processamento de dados gpx\n",
    "        df = json_processed_data(data_folder_path)\n",
    "\n",
    "    elif first_file.endswith('.fit'):\n",
    "        # Criação do Dataframe a partir da função de processamento de dados gpx\n",
    "        df = fit_processed_data(data_folder_path)\n",
    "    \n",
    "    df_athlete_activity = activities_time_frequency(df)\n",
    "\n",
    "    # Adição de uma coluna athlete_id para identificar os dados de cada atleta\n",
    "    df_athlete_activity.insert(0, 'athlete_id', athlete_id)\n",
    "\n",
    "    # Concatenação dos valores de cada atleta por id a um Dataframe\n",
    "    df_athletes_activities = pd.concat([df_athletes_activities, df_athlete_activity])\n",
    "\n",
    "df_athletes_activities.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_athletes_activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "g = sns.countplot(df_athletes_activities, hue=\"activity_type\", x='athlete_id')\n",
    "g.legend().set_title(None)\n",
    "plt.xlabel('Values by Athlete id')\n",
    "plt.ylabel('Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_athletes_activities_new = df_athletes_activities[['athlete_id', 'activity_date', 'activity_type','days_between_activities']]\n",
    "\n",
    "df_athletes_activities_new['activity_type'] = (df_athletes_activities_new['activity_type'] == 'Activity') * 1\n",
    "df_athletes_activities_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de atividades num período específico de dias\n",
    "activity_days = 7\n",
    "\n",
    "# Somando o número de atividades dentro desse período de dias em uma janela deslizante, por atleta\n",
    "df_athletes_activities_new['activities_moving_sum'] = [values for values in df_athletes_activities_new.groupby('athlete_id')['activity_type'].rolling(activity_days).sum()]\n",
    "\n",
    "df_athletes_activities_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para adicionar os exemplos\n",
    "examples_dict = []\n",
    "\n",
    "# Lista com o id de cada atleta\n",
    "athlete_ids = df_athletes_activities_new['athlete_id'].unique()\n",
    "\n",
    "# Quantidade de atividades para estar dentro do período específico\n",
    "activities_qtd = 5\n",
    "\n",
    "# Iteração a partir do id do atleta\n",
    "for athlete_id in athlete_ids:\n",
    "    # Inicializando com periodo ativo como Falso\n",
    "    active_period = False\n",
    "    # Atribuindo a uma variável o dataframe filtrado por id do atleta\n",
    "    df_athlete = df_athletes_activities_new.loc[df_athletes_activities_new['athlete_id'] == athlete_id]\n",
    "\n",
    "    # Iteração pelas linhas com a série de cada atleta por id\n",
    "    for index, row in df_athlete.iterrows():\n",
    "        # Condição para caso a soma de atividades no periodo específico seja >= activities_qtd, se inicializa o periodo ativo\n",
    "        if (row['activities_moving_sum'] >= activities_qtd) & (active_period == False):\n",
    "            active_period = True\n",
    "            active_period_dict = {'athlete_id': athlete_id, 'start': row['activity_date']}\n",
    "\n",
    "        # Condição para finalizar o período ativo caso a soma de atividade no período ativo seja igual 0\n",
    "        elif (row['activities_moving_sum'] == 0) & (active_period == True):\n",
    "            active_period_dict['end'] = row['activity_date']\n",
    "            active_period_dict['data'] = df_athlete[(df_athlete['activity_date'] >= active_period_dict['start']) & (df_athlete['activity_date'] <= active_period_dict['end'])].reset_index(drop=True)\n",
    "            active_period = False    \n",
    "            examples_dict.append(active_period_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe com os dados dos atletas que tiveram inicio e fim de períodos ativos para compor exemplos\n",
    "df_examples = pd.DataFrame(examples_dict)\n",
    "df_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_examples_train, df_examples_test = train_test_split(df_examples, test_size=0.2, random_state=123)\n",
    "df_examples_train.reset_index(drop=True, inplace=True)\n",
    "df_examples_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_examples_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_examples_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ADWIN '''\n",
    "adwin_params_dict = {'delta': [0.0001, 0.005, 0.001, 0.05, 0.01],\n",
    "                     'min_window_length': [5, 10, 20, 30, 40],\n",
    "                     'clock': [1, 2, 3, 4, 5],\n",
    "                     'max_buckets': [5, 10, 15, 20, 25],\n",
    "                     'grace_period': [5, 10, 15, 20, 25]}\n",
    "\n",
    "''' KSWIN '''\n",
    "kswin_params_dict = {'alpha': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "                     'window_size':[100, 200, 300, 400, 500],\n",
    "                     'stat_size': [5, 10, 15, 20, 25],\n",
    "                     'seed': [321]}\n",
    "\n",
    "''' Page Hinkley '''\n",
    "ph_params_dict = {'delta': [0.0001, 0.005, 0.001, 0.05, 0.01],\n",
    "                  'min_instances': [30, 50, 100, 200, 300],\n",
    "                  'threshold': [1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "                  'alpha': [0.5, 1.0, 1.5, 2.0, 2.5]}\n",
    "\n",
    "\n",
    "products = [['ADWIN', [dict(zip(('delta', 'min_window_length', 'clock', 'max_buckets', 'grace_period'), (i,j,k,w,z))) for i,j,k,w,z in product(adwin_params_dict['delta'], adwin_params_dict['min_window_length'], adwin_params_dict['clock'], adwin_params_dict['max_buckets'], adwin_params_dict['grace_period'])]],\n",
    "            ['KSWIN', [dict(zip(('alpha', 'window_size', 'stat_size', 'seed'), (i,j,k,w))) for i,j,k,w in product(kswin_params_dict['alpha'], kswin_params_dict['window_size'], kswin_params_dict['stat_size'], kswin_params_dict['seed'])]],\n",
    "            ['PageHinkley', [dict(zip(('delta', 'min_instances', 'threshold', 'alpha'), (i,j,k,w))) for i,j,k,w in product(ph_params_dict['delta'], ph_params_dict['min_instances'], ph_params_dict['threshold'], ph_params_dict['alpha'])]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(products[0][1]) + len(products[1][1]) + len(products[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor para criar o range de drifts como TP\n",
    "x = 3\n",
    "\n",
    "# Contador para cada paramêtro utilizado nos métodos para cada exemplo\n",
    "param_combination_id = 0\n",
    "\n",
    "# Contador para identicar o exemplo processado\n",
    "example_id = 0\n",
    "\n",
    "# Performance resultada com a função de detecção de drift\n",
    "train_results = []\n",
    "\n",
    "# Iteração pela lista products contendo na primeira posição o nome do método e na segunda as combinações de parâmetros\n",
    "for drift_method, params in products:\n",
    "    # Iteração pela combinação de parâmetros para trabalhar com elas separadamente                   \n",
    "    for param in params:\n",
    "        # Iteração por cada df contendo um exemplo\n",
    "        for df_example_train in df_examples_train['data']:\n",
    "            # Condição para detectar drift com as combinações de parâmetros caso o método seja ADWIN\n",
    "            if drift_method == 'ADWIN':\n",
    "                drift_detection(df_example_train, drift.ADWIN(**param), train_results, param, drift_method, x, param_combination_id, example_id) \n",
    "\n",
    "            # Condição para detectar drift com as combinações de parâmetros caso o método seja KSWIN\n",
    "            elif drift_method == 'KSWIN':\n",
    "                drift_detection(df_example_train, drift.KSWIN(**param), train_results, param, drift_method, x, param_combination_id, example_id)\n",
    "                \n",
    "            # Condição para detectar drift com as combinações de parâmetros caso o método seja Page Hinkley\n",
    "            elif drift_method == 'PageHinkley':\n",
    "                drift_detection(df_example_train, drift.PageHinkley(**param), train_results, param, drift_method, x, param_combination_id, example_id)\n",
    "            \n",
    "            example_id += 1\n",
    "\n",
    "        param_combination_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_train = pd.DataFrame(train_results)\n",
    "df_results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_train_new = df_results_train.groupby('Parameter Combination id').agg({'TP': 'sum', 'TN': 'sum', 'FP': 'sum', 'FN': 'sum'})\n",
    "df_results_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_results_train_new.iterrows():\n",
    "    \n",
    "    df_results_train_new.loc[index, 'Precision'] = metrics(row['TP'], row['FP'], row['TN'], row['FN'])[0]\n",
    "    df_results_train_new.loc[index, 'Recall'] = metrics(row['TP'], row['FP'], row['TN'], row['FN'])[1]\n",
    "    df_results_train_new.loc[index, 'F1-score'] = metrics(row['TP'], row['FP'], row['TN'], row['FN'])[2]\n",
    " \n",
    "df_results_train_metrics = df_results_train_new.reset_index()\n",
    "df_results_train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_train_metrics[['FN', 'FP', 'TP']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_train_metrics[df_results_train_metrics['F1-score'] == df_results_train_metrics['F1-score'].max()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
